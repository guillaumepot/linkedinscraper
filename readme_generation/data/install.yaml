# Install
title_install: "üõ†Ô∏è Installation"
subtitle_prerequisites: "üìã Prerequisites"
text_prerequisites: |
  - Python 3.12.3+
  - Docker and Docker Compose
  - Elasticsearch 8.11.0+
  - Kibana 8.11.0+ (optional, for data visualization)


subtitle_installation_guide: "‚öôÔ∏è Installation Guide"
installation_guide_chapter_1: "1. Clone the Repository"
installation_guide_chapter_1_text_1: |
    ```bash
    git clone <repository-url>
    cd linkedinscraper
    ```

installation_guide_chapter_2: "2. Set Up Python Environment"
installation_guide_chapter_2_text_1: |
  ```bash
  # Create virtual environment (best to use uv)
  uv sync
  # OR python venv
  python -m venv .venv
  source .venv/bin/activate  # On Windows: .venv\Scripts\activate
  pip install -r requirements.txt # requirements.txt must be generated from pyproject.toml
  ```

installation_guide_chapter_3: "3. Edit configuration files"
installation_guide_chapter_3_text_1: |
  Edit `preferences.yaml` to customize your job search preferences:

  ```yaml
  search_queries:
    - keywords: "Data Engineer"
      location: "Your Location"
      f_WT: ""  # Work type: "" (Any), "0" (On-Site), "1" (Hybrid), "2" (Remote)

  title_include: ["Data", "Engineer", "Scientist", "Machine Learning"]
  title_exclude: ["frontend", "react.js", "internship"]
  company_exclude: ["CompanyToAvoid"]
  languages: ["en", "fr"]
  max_age: 7  # Maximum job age in days
  ```

installation_guide_chapter_4: "4. Start services"
installation_guide_chapter_4_text_1: |
    ```bash
    docker-compose up -d
    ```

    This will start:
    - Elasticsearch on `http://localhost:9200`
    - Kibana on `http://localhost:5601`
    - Flask on `http://localhost:5001`

installation_guide_chapter_5: "5. Configure OpenAI (Optional)"
installation_guide_chapter_5_text_1: |
  For AI-powered features, add your OpenAI configuration to `preferences.yaml`:

  ```yaml
  OpenAI:
    API_KEY: "your-openai-api-key"
    Model: "gpt-3.5-turbo"
    resume_path: "/path/to/your/resume.pdf"
  ```

installation_guide_chapter_6: "5. Configure scraper (Optional)"
installation_guide_chapter_6_text_1: |
  Scraper can be configured: `src/job_scraping/config.json`:
  ```json
  {
    "BeautifulSoupEngine": {
      "proxies": {
        "http": "http://proxy:port",
        "https": "https://proxy:port" 
      },
      "headers": {
        "User-Agent": "Your-User-Agent"
      },
      "rounds": 3,
      "pages_to_scrape": 10,
      "max_age": "r84600",
      "request_timeout": 10,
      "max_retry": 3,
      "retry_delay": 5
    },
    "ElasticsearchEngine": {
      "hosts": "http://localhost:9200",
      "verify_certs": false,
      "use_ssl": false,
      "ca_certs": null,
      "basic_auth": null,
      "indexes": ["jobs"]
    }
  }
  ```

